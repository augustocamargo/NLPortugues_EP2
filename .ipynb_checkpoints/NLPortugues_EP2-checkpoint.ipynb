{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('portuguese')\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('portuguese')\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base original da B2W, sem cortes.\n",
    "b2wCorpus = pd.read_csv(\"B2W-Reviews01.csv\",\";\",usecols=['review_text','overall_rating'])\n",
    "print(b2wCorpus.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função de pré-processamento\n",
    "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "def preprocess(text, stem=False):\n",
    "  text = unidecode(text)\n",
    "  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
    "  text = re.sub(\"\\d+\", \"\", text)\n",
    "  text = re.sub(r'(?:^| )\\w(?:$| )', ' ', text).strip()\n",
    "  tokens = []\n",
    "  for token in text.split():\n",
    "    if token not in stop_words:\n",
    "      if stem:\n",
    "        tokens.append(stemmer.stem(token))\n",
    "      else:\n",
    "        tokens.append(token)\n",
    "  return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pré-processamento\n",
    "b2wCorpus.review_text = b2wCorpus.review_text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b2wCorpus.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpus.overall_rating .value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Words = [len(linha.split()) for linha in b2wCorpus[\"review_text\"]]\n",
    "print(Words)\n",
    "plt.hist(Words, len(Words))\n",
    "plt.xlim(xmin=0, xmax = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
