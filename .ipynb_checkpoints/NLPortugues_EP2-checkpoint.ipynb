{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('portuguese')\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "stemmer = SnowballStemmer('portuguese')\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from keras.regularizers import l2\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base original da B2W, sem cortes + clean de overall_rating\n",
    "b2wCorpus = pd.read_csv(\"B2W-Reviews01.csv\",\";\",usecols=['review_text','overall_rating'])\n",
    "\n",
    "# Filtro\n",
    "d = b2wCorpus.index[b2wCorpus[\"overall_rating\"] < 1].tolist()\n",
    "b2wCorpus=b2wCorpus.drop(b2wCorpus.index[d])\n",
    "d = b2wCorpus.index[b2wCorpus[\"overall_rating\"] > 5].tolist()\n",
    "b2wCorpus=b2wCorpus.drop(b2wCorpus.index[d])\n",
    "\n",
    "print(b2wCorpus.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanning function\n",
    "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "def preprocess(text, stem=False):\n",
    "  text = unidecode(text)\n",
    "  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
    "  text = re.sub(\"\\d+\", \"\", text)\n",
    "  text = re.sub(r'(?:^| )\\w(?:$| )', ' ', text).strip()\n",
    "  tokens = []\n",
    "  for token in text.split():\n",
    "    if token not in stop_words:\n",
    "      if stem:\n",
    "        tokens.append(stemmer.stem(token))\n",
    "      else:\n",
    "        tokens.append(token)\n",
    "  return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanning exec\n",
    "b2wCorpus.review_text = b2wCorpus.review_text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b2wCorpus.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpus.overall_rating .value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partilha\n",
    "b2wCorpus = b2wCorpus.sample(frac=1).reset_index(drop=True)\n",
    "print(b2wCorpus.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograma de palavras x qtd de linhas\n",
    "Words = [len(linha.split()) for linha in b2wCorpus[\"review_text\"] if len(linha.split()) <=60 ]\n",
    "plt.style.use('ggplot')\n",
    "plt.hist(Words, bins=[0,5,10,15,20,25,30,35,40,45,50,55,60])\n",
    "plt.show()\n",
    "print(len(Words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codifica\n",
    "N =  200001\n",
    "with open(\"cbow_s50.txt\", \"r\",encoding='utf-8') as file:\n",
    "    head = [next(file) for x in range(N)]\n",
    "\n",
    "head[0] = str(N-1)+ \" \" + \"50\"+ \"\\n\" # Conserta contagem de palavras\n",
    "with open(\"word2vec_200k.txt\", \"w\",encoding='utf-8') as file:\n",
    "    for line in head:\n",
    "        file.write(line)\n",
    "\n",
    "def vocaIndex(lista, stem=False):\n",
    "    for indice in range(len(lista)):\n",
    "        text=lista[indice].lower()\n",
    "        if text in model.vocab:\n",
    "             lista[indice] = model.vocab[text].index\n",
    "        else: \n",
    "             lista[indice] = '0'\n",
    "    return lista\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('word2vec_200k.txt')\n",
    "\n",
    "def codifica(text, stem=False):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = vocaIndex(tokens)\n",
    "    return tokens\n",
    "\n",
    "b2wCorpus.review_text = b2wCorpus.review_text.apply(lambda x: codifica(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpus['ord'] = b2wCorpus.apply(lambda row: len(row.review_text), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b2wCorpus = b2wCorpus[b2wCorpus.ord != 0]\n",
    "b2wCorpus = b2wCorpus.drop(b2wCorpus[b2wCorpus.ord < 10].index)\n",
    "b2wCorpus = b2wCorpus.drop(b2wCorpus[b2wCorpus.ord > 50].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpus['overall_rating'] = b2wCorpus.overall_rating.apply(lambda x: x - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpus.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(b2wCorpus.review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b2wCorpus.review_text.str.rjust(width=50, fillchar='0')\n",
    "#np.reshape(y_train,(-1))\n",
    "\n",
    "b2wCorpus.review_text = keras.preprocessing.sequence.pad_sequences(b2wCorpus.apply(lambda row: np.reshape(row.review_text,(-1)), axis=1), maxlen=50, padding='post').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de split\n",
    "def train_validate_test_split(df, train_percent=.65, validate_percent=.1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpusTrain, b2wCorpusValidate, b2wCorpusTest = train_validate_test_split(b2wCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpusTrain=b2wCorpusTrain.reindex(b2wCorpusTrain['ord'].sort_values(ascending=False).index)\n",
    "b2wCorpusTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b2wCorpusValidate=b2wCorpusValidate.reindex(b2wCorpusValidate['ord'].sort_values(ascending=False).index)\n",
    "b2wCorpusValidate.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpusTest=b2wCorpusTest.reindex(b2wCorpusTest['ord'].sort_values(ascending=False).index)\n",
    "b2wCorpusTest.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(b2wCorpus.review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino, Validação e teste\n",
    "RANDOM_SEED = 42\n",
    "x_train =  [ emb for emb in b2wCorpusTrain.review_text]\n",
    "y_train =   b2wCorpusTrain.overall_rating\n",
    "x_val = [ emb for emb in b2wCorpusValidate.review_text ]\n",
    "y_val = b2wCorpusValidate.overall_rating\n",
    "x_train = np.asarray(x_train)\n",
    "x_val =np.asarray(x_val)\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "model = KeyedVectors.load_word2vec_format('word2vec_200k.txt')\n",
    "emb = model.get_keras_embedding()\n",
    "emb.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "SEQUENCE_MAXLEN = 50\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape=(SEQUENCE_MAXLEN, )))\n",
    "model.add(emb)\n",
    "\n",
    "model.add(keras.layers.LSTM(128, dropout=0.5))\n",
    "#model.add(Dropout(0.50))\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "#opt = tf.keras.optimizers.SGD(learning_rate=.1, momentum=.5)\n",
    "#opt = tf.keras.optimizers.Adamax(learning_rate=0.01, beta_1=.9, beta_2=.9, epsilon=1e-07, name=\"Adamax\")\n",
    "#model.compile(optimizer=opt, loss=categorical_crossentropy, metrics=['acc', 'mae'])\n",
    "opt=\"adam\"\n",
    "model.compile(optimizer=opt,loss=sparse_categorical_crossentropy, metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x= x_train, y=y_train, batch_size=32, epochs=50, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='valid')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='valid')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
